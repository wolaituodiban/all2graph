{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a02848",
   "metadata": {},
   "source": [
    "# spark取数教程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc1365",
   "metadata": {},
   "source": [
    "在工业应用中，常常需要将大量的数据处理成json格式，这是个大数据问题，并不是特别容易<br>\n",
    "本教程提供一个spark sql的模版供参考"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d2098f",
   "metadata": {},
   "source": [
    "假设有一个样本表sample，包含如下字段<br>\n",
    "uid, timestamp\n",
    "\n",
    "有一个数据表data，包含如下字段<br>\n",
    "uid, timestamp, col1, col2\n",
    "\n",
    "那么sql模版如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c1e14fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"select\n",
    "  a.uid,\n",
    "  a.timestamp,\n",
    "  to_json(\n",
    "    collect_list(\n",
    "      struct(\n",
    "        b.timestamp, \n",
    "        b.col1,\n",
    "        b.col2\n",
    "      )\n",
    "    )\n",
    "  ) data\n",
    "from\n",
    "  sample a\n",
    "  left join \n",
    "  data b\n",
    "  on a.uid = b.uid\n",
    "  and b.timestamp <= a.timestamp\n",
    "group by\n",
    "  a.uid,\n",
    "  a.timestamp\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a043d30",
   "metadata": {},
   "source": [
    "假设数据已经被存储在一个叫做data.csv的文件里了<br>\n",
    "使用pandas读取的时候可能需要配置一些参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5989d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "df = pd.read_csv('data.csv', escapechar='\\\\', quoting=csv.QUOTE_MINIMAL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag37",
   "language": "python",
   "name": "ag37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
